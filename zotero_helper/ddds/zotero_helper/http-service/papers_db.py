citations = {
    "http%3A%2F%2Farxiv.org%2Fabs%2F1909.09484v1": [
        {
            "key": "K44L5RV4",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Tian",
                    "lastName": "Lan",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xianling",
                    "lastName": "Mao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Heyan",
                    "lastName": "Huang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Generative Dialog Policy for Task-oriented Dialog Systems",
            "date": "2019-09-17",
            "abstractNote": "There is an increasing demand for task-oriented dialogue systems which can assist users in various activities such as booking tickets and restaurant reservations. In order to complete dialogues effectively, dialogue policy plays a key role in task-oriented dialogue systems. As far as we know, the existing task-oriented dialogue systems obtain the dialogue policy through classification, which can assign either a dialogue act and its corresponding parameters or multiple dialogue acts without their corresponding parameters for a dialogue action. In fact, a good dialogue policy should construct multiple dialogue acts and their corresponding parameters at the same time. However, it's hard for existing classification-based methods to achieve this goal. Thus, to address the issue above, we propose a novel generative dialogue policy learning method. Specifically, the proposed method uses attention mechanism to find relevant segments of given dialogue context and input utterance and then constructs the dialogue policy by a seq2seq way for task-oriented dialogue systems. Extensive experiments on two benchmark datasets show that the proposed model significantly outperforms the state-of-the-art baselines. In addition, we have publicly released our codes.",
            "url": "http://arxiv.org/abs/1909.09484",
            "publicationTitle": "arXiv:1909.09484 [cs]",
            "extra": "arXiv: 1909.09484\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2110.08032v1": [
        {
            "key": "J2ILIYSL",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Xinyan",
                    "lastName": "Zhao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Bin",
                    "lastName": "He",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yasheng",
                    "lastName": "Wang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yitong",
                    "lastName": "Li",
                    "creatorType": "author"
                },
                {
                    "firstName": "Fei",
                    "lastName": "Mi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yajiao",
                    "lastName": "Liu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xin",
                    "lastName": "Jiang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Qun",
                    "lastName": "Liu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Huanhuan",
                    "lastName": "Chen",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "UniDS: A Unified Dialogue System for Chit-Chat and Task-oriented Dialogues",
            "date": "2021-10-15",
            "abstractNote": "With the advances in deep learning, tremendous progress has been made with chit-chat dialogue systems and task-oriented dialogue systems. However, these two systems are often tackled separately in current methods. To achieve more natural interaction with humans, a dialogue agent needs to be capable of both chatting and accomplishing tasks. To this end, we propose a unified dialogue system (UniDS) with the two aforementioned skills. In particular, we design a unified dialogue data schema, compatible for both chit-chat and task-oriented dialogues, and we train UniDS with mixed dialogue data from a pretrained chit-chat dialogue model. Without adding extra parameters to SOTA baselines, UniDS can alternatively handle chit-chat and task-oriented dialogues in a unified framework. Experimental results demonstrate that the proposed UniDS works comparably well as the pure chit-chat system, and it outperforms state-of-the-art task-oriented dialogue systems. More importantly, UniDS achieves better robustness as it is able to smoothly switch between two types of dialogues. These results demonstrate the feasibility and potential of building an one-for-all dialogue system.",
            "url": "http://arxiv.org/abs/2110.08032",
            "publicationTitle": "arXiv:2110.08032 [cs]",
            "extra": "arXiv: 2110.08032\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "UniDS"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1106.1817v1": [
        {
            "key": "F5P8MGVU",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "A.",
                    "lastName": "Gorin",
                    "creatorType": "author"
                },
                {
                    "firstName": "I.",
                    "lastName": "Langkilde-Geary",
                    "creatorType": "author"
                },
                {
                    "firstName": "M. A.",
                    "lastName": "Walker",
                    "creatorType": "author"
                },
                {
                    "firstName": "J.",
                    "lastName": "Wright",
                    "creatorType": "author"
                },
                {
                    "firstName": "H. Wright",
                    "lastName": "Hastie",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Automatically Training a Problematic Dialogue Predictor for a Spoken Dialogue System",
            "date": "2002-05-01",
            "abstractNote": "Spoken dialogue systems promise efficient and natural access to a large variety of information sources and services from any phone. However, current spoken dialogue systems are deficient in their strategies for preventing, identifying and repairing problems that arise in the conversation. This paper reports results on automatically training a Problematic Dialogue Predictor to predict problematic human-computer dialogues using a corpus of 4692 dialogues collected with the 'How May I Help You' (SM) spoken dialogue system. The Problematic Dialogue Predictor can be immediately applied to the system's decision of whether to transfer the call to a human customer care agent, or be used as a cue to the system's dialogue manager to modify its behavior to repair problems, and even perhaps, to prevent them. We show that a Problematic Dialogue Predictor using automatically-obtainable features from the first two exchanges in the dialogue can predict problematic dialogues 13.2% more accurately than the baseline.",
            "url": "http://arxiv.org/abs/1106.1817",
            "DOI": "10.1613/jair.971",
            "publicationTitle": "Journal of Artificial Intelligence Research",
            "extra": "arXiv: 1106.1817\nversion: 1",
            "volume": "16",
            "pages": "293\u2013319",
            "ISSN": "1076-9757",
            "journalAbbreviation": "jair",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2Fcmp-lg%2F9505013v1": [
        {
            "key": "S9THNFK2",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Norbert",
                    "lastName": "Reithinger",
                    "creatorType": "author"
                },
                {
                    "firstName": "Elisabeth",
                    "lastName": "Maier",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Utilizing Statistical Dialogue Act Processing in Verbmobil",
            "date": "1995-05-05",
            "abstractNote": "In this paper, we present a statistical approach for dialogue act processing in the dialogue component of the speech-to-speech translation system \\vm. Statistics in dialogue processing is used to predict follow-up dialogue acts. As an application example we show how it supports repair when unexpected dialogue states occur.",
            "url": "http://arxiv.org/abs/cmp-lg/9505013",
            "publicationTitle": "arXiv:cmp-lg/9505013",
            "extra": "arXiv: cmp-lg/9505013\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1907.00684v1": [
        {
            "key": "Q8F4EN7J",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Juliana",
                    "lastName": "Miehle",
                    "creatorType": "author"
                },
                {
                    "firstName": "Louisa",
                    "lastName": "Pragst",
                    "creatorType": "author"
                },
                {
                    "firstName": "Wolfgang",
                    "lastName": "Minker",
                    "creatorType": "author"
                },
                {
                    "firstName": "Stefan",
                    "lastName": "Ultes",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Human-Computer Interaction",
                    "type": 1
                }
            ],
            "title": "Enabling Dialogue Management with Dynamically Created Dialogue Actions",
            "date": "2019-07-01",
            "abstractNote": "In order to take up the challenge of realising user-adaptive system behaviour, we present an extension for the existing OwlSpeak Dialogue Manager which enables the handling of dynamically created dialogue actions. This leads to an increase in flexibility which can be used for adaptation tasks. After the implementation of the modifications and the integration of the Dialogue Manager into a full Spoken Dialogue System, an evaluation of the system has been carried out. The results indicate that the participants were able to conduct meaningful dialogues and that the system performs satisfactorily, showing that the implementation of the Dialogue Manager was successful.",
            "url": "http://arxiv.org/abs/1907.00684",
            "publicationTitle": "arXiv:1907.00684 [cs]",
            "extra": "arXiv: 1907.00684\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1306.4134v1": [
        {
            "key": "DRQ5Z9LH",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Suket",
                    "lastName": "Arora",
                    "creatorType": "author"
                },
                {
                    "firstName": "Kamaljeet",
                    "lastName": "Batra",
                    "creatorType": "author"
                },
                {
                    "firstName": "Sarabjit",
                    "lastName": "Singh",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Dialogue System: A Brief Review",
            "date": "2013-06-18",
            "abstractNote": "A Dialogue System is a system which interacts with human in natural language. At present many universities are developing the dialogue system in their regional language. This paper will discuss about dialogue system, its components, challenges and its evaluation. This paper helps the researchers for getting info regarding dialogues system.",
            "url": "http://arxiv.org/abs/1306.4134",
            "publicationTitle": "arXiv:1306.4134 [cs]",
            "extra": "arXiv: 1306.4134\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Dialogue System"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2105.03571v2": [
        {
            "key": "CTTR8UBP",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Puhai",
                    "lastName": "Yang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Heyan",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xian-Ling",
                    "lastName": "Mao",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Comprehensive Study: How the Context Information of Different Granularity Affects Dialogue State Tracking?",
            "date": "2021-05-30",
            "abstractNote": "Dialogue state tracking (DST) plays a key role in task-oriented dialogue systems to monitor the user's goal. In general, there are two strategies to track a dialogue state: predicting it from scratch and updating it from previous state. The scratch-based strategy obtains each slot value by inquiring all the dialogue history, and the previous-based strategy relies on the current turn dialogue to update the previous dialogue state. However, it is hard for the scratch-based strategy to correctly track short-dependency dialogue state because of noise; meanwhile, the previous-based strategy is not very useful for long-dependency dialogue state tracking. Obviously, it plays different roles for the context information of different granularity to track different kinds of dialogue states. Thus, in this paper, we will study and discuss how the context information of different granularity affects dialogue state tracking. First, we explore how greatly different granularities affect dialogue state tracking. Then, we further discuss how to combine multiple granularities for dialogue state tracking. Finally, we apply the findings about context granularity to few-shot learning scenario. Besides, we have publicly released all codes.",
            "url": "http://arxiv.org/abs/2105.03571",
            "publicationTitle": "arXiv:2105.03571 [cs]",
            "extra": "arXiv: 2105.03571\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Comprehensive Study"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2Fcs%2F0312052v1": [
        {
            "key": "D8447NKR",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Paul",
                    "lastName": "Piwek",
                    "creatorType": "author"
                },
                {
                    "firstName": "Kees",
                    "lastName": "van Deemter",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "I.2.7",
                    "type": 1
                }
            ],
            "title": "Dialogue as Discourse: Controlling Global Properties of Scripted Dialogue",
            "date": "2003-12-22",
            "abstractNote": "This paper explains why scripted dialogue shares some crucial properties with discourse. In particular, when scripted dialogues are generated by a Natural Language Generation system, the generator can apply revision strategies that cannot normally be used when the dialogue results from an interaction between autonomous agents (i.e., when the dialogue is not scripted). The paper explains that the relevant revision operators are best applied at the level of a dialogue plan and discusses how the generator may decide when to apply a given revision operator.",
            "url": "http://arxiv.org/abs/cs/0312052",
            "publicationTitle": "arXiv:cs/0312052",
            "extra": "arXiv: cs/0312052\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Dialogue as Discourse"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1711.10712v2": [
        {
            "key": "QFBTJ5C8",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Bing",
                    "lastName": "Liu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Gokhan",
                    "lastName": "Tur",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dilek",
                    "lastName": "Hakkani-Tur",
                    "creatorType": "author"
                },
                {
                    "firstName": "Pararth",
                    "lastName": "Shah",
                    "creatorType": "author"
                },
                {
                    "firstName": "Larry",
                    "lastName": "Heck",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "End-to-End Optimization of Task-Oriented Dialogue Model with Deep Reinforcement Learning",
            "date": "2017-11-30",
            "abstractNote": "In this paper, we present a neural network based task-oriented dialogue system that can be optimized end-to-end with deep reinforcement learning (RL). The system is able to track dialogue state, interface with knowledge bases, and incorporate query results into agent's responses to successfully complete task-oriented dialogues. Dialogue policy learning is conducted with a hybrid supervised and deep RL methods. We first train the dialogue agent in a supervised manner by learning directly from task-oriented dialogue corpora, and further optimize it with deep RL during its interaction with users. In the experiments on two different dialogue task domains, our model demonstrates robust performance in tracking dialogue state and producing reasonable system responses. We show that deep RL based optimization leads to significant improvement on task success rate and reduction in dialogue length comparing to supervised training model. We further show benefits of training task-oriented dialogue model end-to-end comparing to component-wise optimization with experiment results on dialogue simulations and human evaluations.",
            "url": "http://arxiv.org/abs/1711.10712",
            "publicationTitle": "arXiv:1711.10712 [cs]",
            "extra": "arXiv: 1711.10712\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1811.10728v1": [
        {
            "key": "3ZTULWBN",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Hisao",
                    "lastName": "Katsumi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Takuya",
                    "lastName": "Hiraoka",
                    "creatorType": "author"
                },
                {
                    "firstName": "Koichiro",
                    "lastName": "Yoshino",
                    "creatorType": "author"
                },
                {
                    "firstName": "Kazeto",
                    "lastName": "Yamamoto",
                    "creatorType": "author"
                },
                {
                    "firstName": "Shota",
                    "lastName": "Motoura",
                    "creatorType": "author"
                },
                {
                    "firstName": "Kunihiko",
                    "lastName": "Sadamasa",
                    "creatorType": "author"
                },
                {
                    "firstName": "Satoshi",
                    "lastName": "Nakamura",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Optimization of Information-Seeking Dialogue Strategy for Argumentation-Based Dialogue System",
            "date": "2018-11-26",
            "abstractNote": "Argumentation-based dialogue systems, which can handle and exchange arguments through dialogue, have been widely researched. It is required that these systems have sufficient supporting information to argue their claims rationally; however, the systems often do not have enough of such information in realistic situations. One way to fill in the gap is acquiring such missing information from dialogue partners (information-seeking dialogue). Existing information-seeking dialogue systems are based on handcrafted dialogue strategies that exhaustively examine missing information. However, the proposed strategies are not specialized in collecting information for constructing rational arguments. Moreover, the number of system's inquiry candidates grows in accordance with the size of the argument set that the system deal with. In this paper, we formalize the process of information-seeking dialogue as Markov decision processes (MDPs) and apply deep reinforcement learning (DRL) for automatically optimizing a dialogue strategy. By utilizing DRL, our dialogue strategy can successfully minimize objective functions, the number of turns it takes for our system to collect necessary information in a dialogue. We conducted dialogue experiments using two datasets from different domains of argumentative dialogue. Experimental results show that the proposed formalization based on MDP works well, and the policy optimized by DRL outperformed existing heuristic dialogue strategies.",
            "url": "http://arxiv.org/abs/1811.10728",
            "publicationTitle": "arXiv:1811.10728 [cs]",
            "extra": "arXiv: 1811.10728\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2Fcmp-lg%2F9502008v1": [
        {
            "key": "ZBRWWD53",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Jan",
                    "lastName": "Alexandersson",
                    "creatorType": "author"
                },
                {
                    "firstName": "Elisabeth",
                    "lastName": "Maier",
                    "creatorType": "author"
                },
                {
                    "firstName": "Norbert",
                    "lastName": "Reithinger",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "A Robust and Efficient Three-Layered Dialogue Component for a Speech-to-Speech Translation System",
            "date": "1995-02-10",
            "abstractNote": "We present the dialogue component of the speech-to-speech translation system VERBMOBIL. In contrast to conventional dialogue systems it mediates the dialogue while processing maximally 50% of the dialogue in depth. Special requirements like robustness and efficiency lead to a 3-layered hybrid architecture for the dialogue module, using statistics, an automaton and a planner. A dialogue memory is constructed incrementally.",
            "url": "http://arxiv.org/abs/cmp-lg/9502008",
            "publicationTitle": "arXiv:cmp-lg/9502008",
            "extra": "arXiv: cmp-lg/9502008\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1805.00150v1": [
        {
            "key": "3Q3Z6KFE",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Zheng",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Minlie",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zhongzhou",
                    "lastName": "Zhao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Feng",
                    "lastName": "Ji",
                    "creatorType": "author"
                },
                {
                    "firstName": "Haiqing",
                    "lastName": "Chen",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaoyan",
                    "lastName": "Zhu",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Information Retrieval",
                    "type": 1
                },
                {
                    "tag": "68T50",
                    "type": 1
                }
            ],
            "title": "Memory-augmented Dialogue Management for Task-oriented Dialogue Systems",
            "date": "2018-04-30",
            "abstractNote": "Dialogue management (DM) decides the next action of a dialogue system according to the current dialogue state, and thus plays a central role in task-oriented dialogue systems. Since dialogue management requires to have access to not only local utterances, but also the global semantics of the entire dialogue session, modeling the long-range history information is a critical issue. To this end, we propose a novel Memory-Augmented Dialogue management model (MAD) which employs a memory controller and two additional memory structures, i.e., a slot-value memory and an external memory. The slot-value memory tracks the dialogue state by memorizing and updating the values of semantic slots (for instance, cuisine, price, and location), and the external memory augments the representation of hidden states of traditional recurrent neural networks through storing more context information. To update the dialogue state efficiently, we also propose slot-level attention on user utterances to extract specific semantic information for each slot. Experiments show that our model can obtain state-of-the-art performance and outperforms existing baselines.",
            "url": "http://arxiv.org/abs/1805.00150",
            "publicationTitle": "arXiv:1805.00150 [cs]",
            "extra": "arXiv: 1805.00150\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1909.11833v1": [
        {
            "key": "II42PHW8",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Chenguang",
                    "lastName": "Zhu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Michael",
                    "lastName": "Zeng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xuedong",
                    "lastName": "Huang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "SIM: A Slot-Independent Neural Model for Dialogue State Tracking",
            "date": "2019-09-25",
            "abstractNote": "Dialogue state tracking is an important component in task-oriented dialogue systems to identify users' goals and requests as a dialogue proceeds. However, as most previous models are dependent on dialogue slots, the model complexity soars when the number of slots increases. In this paper, we put forward a slot-independent neural model (SIM) to track dialogue states while keeping the model complexity invariant to the number of dialogue slots. The model utilizes attention mechanisms between user utterance and system actions. SIM achieves state-of-the-art results on WoZ and DSTC2 tasks, with only 20% of the model size of previous models.",
            "url": "http://arxiv.org/abs/1909.11833",
            "publicationTitle": "arXiv:1909.11833 [cs]",
            "extra": "arXiv: 1909.11833\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "SIM"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2008.05666v1": [
        {
            "key": "W4NUM935",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Qingkai",
                    "lastName": "Min",
                    "creatorType": "author"
                },
                {
                    "firstName": "Libo",
                    "lastName": "Qin",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zhiyang",
                    "lastName": "Teng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiao",
                    "lastName": "Liu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yue",
                    "lastName": "Zhang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Dialogue State Induction Using Neural Latent Variable Models",
            "date": "2020-07",
            "abstractNote": "Dialogue state modules are a useful component in a task-oriented dialogue system. Traditional methods find dialogue states by manually labeling training corpora, upon which neural models are trained. However, the labeling process can be costly, slow, error-prone, and more importantly, cannot cover the vast range of domains in real-world dialogues for customer service. We propose the task of dialogue state induction, building two neural latent variable models that mine dialogue states automatically from unlabeled customer service dialogue records. Results show that the models can effectively find meaningful slots. In addition, equipped with induced dialogue states, a state-of-the-art dialogue system gives better performance compared with not using a dialogue state module.",
            "url": "http://arxiv.org/abs/2008.05666",
            "DOI": "10.24963/ijcai.2020/532",
            "publicationTitle": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence",
            "extra": "arXiv: 2008.05666\nversion: 1",
            "pages": "3845\u20133852",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2108.10561v1": [
        {
            "key": "JX62B5YV",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Andrea",
                    "lastName": "Madotto",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Machine Learning",
                    "type": 1
                }
            ],
            "title": "Taming the Beast: Learning to Control Neural Conversational Models",
            "date": "2021-08-24",
            "abstractNote": "This thesis investigates the controllability of deep learning-based, end-to-end, generative dialogue systems in both task-oriented and chit-chat scenarios. In particular, we study the different aspects of controlling generative dialogue systems, including controlling styles and topics and continuously adding and combining dialogue skills. In the three decades since the first dialogue system was commercialized, the basic architecture of such systems has remained substantially unchanged, consisting of four pipelined basic components, namely, natural language understanding (NLU), dialogue state tracking (DST), a dialogue manager (DM) and natural language generation (NLG). The dialogue manager, which is the critical component of the modularized system, controls the response content and style. This module is usually programmed by rules and is designed to be highly controllable and easily extendable. With the emergence of powerful \"deep learning\" architectures, end-to-end generative dialogue systems have been proposed to optimize overall system performance and simplify training. However, these systems cannot be easily controlled and extended as the modularized dialogue manager can. This is because a single neural system is used, which is usually a large pre-trained language model (e.g., GPT-2), and thus it is hard to surgically change desirable attributes (e.g., style, topics, etc.). More importantly, uncontrollable dialogue systems can generate offensive and even toxic responses. Therefore, in this thesis, we study controllable methods for end-to-end generative dialogue systems in task-oriented and chit-chat scenarios. Throughout the chapters, we describe 1) how to control the style and topics of chit-chat models, 2) how to continuously control and extend task-oriented dialogue systems, and 3) how to compose and control multi-skill dialogue models.",
            "url": "http://arxiv.org/abs/2108.10561",
            "publicationTitle": "arXiv:2108.10561 [cs]",
            "extra": "arXiv: 2108.10561\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Taming the Beast"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1909.09220v1": [
        {
            "key": "SS9ME2MA",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Yi-An",
                    "lastName": "Lai",
                    "creatorType": "author"
                },
                {
                    "firstName": "Arshit",
                    "lastName": "Gupta",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yi",
                    "lastName": "Zhang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Goal-Embedded Dual Hierarchical Model for Task-Oriented Dialogue Generation",
            "date": "2019-09-19",
            "abstractNote": "Hierarchical neural networks are often used to model inherent structures within dialogues. For goal-oriented dialogues, these models miss a mechanism adhering to the goals and neglect the distinct conversational patterns between two interlocutors. In this work, we propose Goal-Embedded Dual Hierarchical Attentional Encoder-Decoder (G-DuHA) able to center around goals and capture interlocutor-level disparity while modeling goal-oriented dialogues. Experiments on dialogue generation, response generation, and human evaluations demonstrate that the proposed model successfully generates higher-quality, more diverse and goal-centric dialogues. Moreover, we apply data augmentation via goal-oriented dialogue generation for task-oriented dialog systems with better performance achieved.",
            "url": "http://arxiv.org/abs/1909.09220",
            "publicationTitle": "arXiv:1909.09220 [cs]",
            "extra": "arXiv: 1909.09220\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1910.14229v1": [
        {
            "key": "REBEZAZZ",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Yue",
                    "lastName": "Ma",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaojie",
                    "lastName": "Wang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zhenjiang",
                    "lastName": "Dong",
                    "creatorType": "author"
                },
                {
                    "firstName": "Hong",
                    "lastName": "Chen",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Cascaded LSTMs based Deep Reinforcement Learning for Goal-driven Dialogue",
            "date": "2019-10-30",
            "abstractNote": "This paper proposes a deep neural network model for joint modeling Natural Language Understanding (NLU) and Dialogue Management (DM) in goal-driven dialogue systems. There are three parts in this model. A Long Short-Term Memory (LSTM) at the bottom of the network encodes utterances in each dialogue turn into a turn embedding. Dialogue embeddings are learned by a LSTM at the middle of the network, and updated by the feeding of all turn embeddings. The top part is a forward Deep Neural Network which converts dialogue embeddings into the Q-values of different dialogue actions. The cascaded LSTMs based reinforcement learning network is jointly optimized by making use of the rewards received at each dialogue turn as the only supervision information. There is no explicit NLU and dialogue states in the network. Experimental results show that our model outperforms both traditional Markov Decision Process (MDP) model and single LSTM with Deep Q-Network on meeting room booking tasks. Visualization of dialogue embeddings illustrates that the model can learn the representation of dialogue states.",
            "url": "http://arxiv.org/abs/1910.14229",
            "publicationTitle": "arXiv:1910.14229 [cs]",
            "extra": "arXiv: 1910.14229\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1912.00819v3": [
        {
            "key": "WIWL9I62",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Chandrakant",
                    "lastName": "Bothe",
                    "creatorType": "author"
                },
                {
                    "firstName": "Cornelius",
                    "lastName": "Weber",
                    "creatorType": "author"
                },
                {
                    "firstName": "Sven",
                    "lastName": "Magg",
                    "creatorType": "author"
                },
                {
                    "firstName": "Stefan",
                    "lastName": "Wermter",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Robotics",
                    "type": 1
                }
            ],
            "title": "EDA: Enriching Emotional Dialogue Acts using an Ensemble of Neural Annotators",
            "date": "2020-03-16",
            "abstractNote": "The recognition of emotion and dialogue acts enriches conversational analysis and help to build natural dialogue systems. Emotion interpretation makes us understand feelings and dialogue acts reflect the intentions and performative functions in the utterances. However, most of the textual and multi-modal conversational emotion corpora contain only emotion labels but not dialogue acts. To address this problem, we propose to use a pool of various recurrent neural models trained on a dialogue act corpus, with and without context. These neural models annotate the emotion corpora with dialogue act labels, and an ensemble annotator extracts the final dialogue act label. We annotated two accessible multi-modal emotion corpora: IEMOCAP and MELD. We analyzed the co-occurrence of emotion and dialogue act labels and discovered specific relations. For example, Accept/Agree dialogue acts often occur with the Joy emotion, Apology with Sadness, and Thanking with Joy. We make the Emotional Dialogue Acts (EDA) corpus publicly available to the research community for further study and analysis.",
            "url": "http://arxiv.org/abs/1912.00819",
            "publicationTitle": "arXiv:1912.00819 [cs]",
            "extra": "arXiv: 1912.00819\nversion: 3",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "EDA"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2009.09427v2": [
        {
            "key": "6E833K2L",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Rongsheng",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yinhe",
                    "lastName": "Zheng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jianzhi",
                    "lastName": "Shao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaoxi",
                    "lastName": "Mao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yadong",
                    "lastName": "Xi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Minlie",
                    "lastName": "Huang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Dialogue Distillation: Open-Domain Dialogue Augmentation Using Unpaired Data",
            "date": "2020-11-10",
            "abstractNote": "Recent advances in open-domain dialogue systems rely on the success of neural models that are trained on large-scale data. However, collecting large-scale dialogue data is usually time-consuming and labor-intensive. To address this data dilemma, we propose a novel data augmentation method for training open-domain dialogue models by utilizing unpaired data. Specifically, a data-level distillation process is first proposed to construct augmented dialogues where both post and response are retrieved from the unpaired data. A ranking module is employed to filter out low-quality dialogues. Further, a model-level distillation process is employed to distill a teacher model trained on high-quality paired data to augmented dialogue pairs, thereby preventing dialogue models from being affected by the noise in the augmented data. Automatic and manual evaluation indicates that our method can produce high-quality dialogue pairs with diverse contents, and the proposed data-level and model-level dialogue distillation can improve the performance of competitive baselines.",
            "url": "http://arxiv.org/abs/2009.09427",
            "publicationTitle": "arXiv:2009.09427 [cs]",
            "extra": "arXiv: 2009.09427\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Dialogue Distillation"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2010.02586v2": [
        {
            "key": "U3Z73ZLI",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Carel",
                    "lastName": "van Niekerk",
                    "creatorType": "author"
                },
                {
                    "firstName": "Michael",
                    "lastName": "Heck",
                    "creatorType": "author"
                },
                {
                    "firstName": "Christian",
                    "lastName": "Geishauser",
                    "creatorType": "author"
                },
                {
                    "firstName": "Hsien-Chin",
                    "lastName": "Lin",
                    "creatorType": "author"
                },
                {
                    "firstName": "Nurul",
                    "lastName": "Lubis",
                    "creatorType": "author"
                },
                {
                    "firstName": "Marco",
                    "lastName": "Moresi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Milica",
                    "lastName": "Ga\u0161i\u0107",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Knowing What You Know: Calibrating Dialogue Belief State Distributions via Ensembles",
            "date": "2020-11-05",
            "abstractNote": "The ability to accurately track what happens during a conversation is essential for the performance of a dialogue system. Current state-of-the-art multi-domain dialogue state trackers achieve just over 55% accuracy on the current go-to benchmark, which means that in almost every second dialogue turn they place full confidence in an incorrect dialogue state. Belief trackers, on the other hand, maintain a distribution over possible dialogue states. However, they lack in performance compared to dialogue state trackers, and do not produce well calibrated distributions. In this work we present state-of-the-art performance in calibration for multi-domain dialogue belief trackers using a calibrated ensemble of models. Our resulting dialogue belief tracker also outperforms previous dialogue belief tracking models in terms of accuracy.",
            "url": "http://arxiv.org/abs/2010.02586",
            "publicationTitle": "arXiv:2010.02586 [cs]",
            "extra": "arXiv: 2010.02586\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Knowing What You Know"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1811.12891v1": [
        {
            "key": "HRI5LT7Z",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Rahul",
                    "lastName": "Goel",
                    "creatorType": "author"
                },
                {
                    "firstName": "Shachi",
                    "lastName": "Paul",
                    "creatorType": "author"
                },
                {
                    "firstName": "Tagyoung",
                    "lastName": "Chung",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jeremie",
                    "lastName": "Lecomte",
                    "creatorType": "author"
                },
                {
                    "firstName": "Arindam",
                    "lastName": "Mandal",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dilek",
                    "lastName": "Hakkani-Tur",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Flexible and Scalable State Tracking Framework for Goal-Oriented Dialogue Systems",
            "date": "2018-11-30",
            "abstractNote": "Goal-oriented dialogue systems typically rely on components specifically developed for a single task or domain. This limits such systems in two different ways: If there is an update in the task domain, the dialogue system usually needs to be updated or completely re-trained. It is also harder to extend such dialogue systems to different and multiple domains. The dialogue state tracker in conventional dialogue systems is one such component - it is usually designed to fit a well-defined application domain. For example, it is common for a state variable to be a categorical distribution over a manually-predefined set of entities (Henderson et al., 2013), resulting in an inflexible and hard-to-extend dialogue system. In this paper, we propose a new approach for dialogue state tracking that can generalize well over multiple domains without incorporating any domain-specific knowledge. Under this framework, discrete dialogue state variables are learned independently and the information of a predefined set of possible values for dialogue state variables is not required. Furthermore, it enables adding arbitrary dialogue context as features and allows for multiple values to be associated with a single state variable. These characteristics make it much easier to expand the dialogue state space. We evaluate our framework using the widely used dialogue state tracking challenge data set (DSTC2) and show that our framework yields competitive results with other state-of-the-art results despite incorporating little domain knowledge. We also show that this framework can benefit from widely available external resources such as pre-trained word embeddings.",
            "url": "http://arxiv.org/abs/1811.12891",
            "publicationTitle": "arXiv:1811.12891 [cs]",
            "extra": "arXiv: 1811.12891\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2012.03118v1": [
        {
            "key": "F8LM2R9S",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Takashi",
                    "lastName": "Kodama",
                    "creatorType": "author"
                },
                {
                    "firstName": "Ribeka",
                    "lastName": "Tanaka",
                    "creatorType": "author"
                },
                {
                    "firstName": "Sadao",
                    "lastName": "Kurohashi",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Modeling and Utilizing User's Internal State in Movie Recommendation Dialogue",
            "date": "2020-12-05",
            "abstractNote": "Intelligent dialogue systems are expected as a new interface between humans and machines. Such an intelligent dialogue system should estimate the user's internal state (UIS) in dialogues and change its response appropriately according to the estimation result. In this paper, we model the UIS in dialogues, taking movie recommendation dialogues as examples, and construct a dialogue system that changes its response based on the UIS. Based on the dialogue data analysis, we model the UIS as three elements: knowledge, interest, and engagement. We train the UIS estimators on a dialogue corpus with the modeled UIS's annotations. The estimators achieved high estimation accuracy. We also design response change rules that change the system's responses according to each UIS. We confirmed that response changes using the result of the UIS estimators improved the system utterances' naturalness in both dialogue-wise evaluation and utterance-wise evaluation.",
            "url": "http://arxiv.org/abs/2012.03118",
            "publicationTitle": "arXiv:2012.03118 [cs]",
            "extra": "arXiv: 2012.03118\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1601.04574v1": [
        {
            "key": "XM6HEMJX",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Heriberto",
                    "lastName": "Cuay\u00e1huitl",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Machine Learning",
                    "type": 1
                }
            ],
            "title": "SimpleDS: A Simple Deep Reinforcement Learning Dialogue System",
            "date": "2016-01-18",
            "abstractNote": "This paper presents 'SimpleDS', a simple and publicly available dialogue system trained with deep reinforcement learning. In contrast to previous reinforcement learning dialogue systems, this system avoids manual feature engineering by performing action selection directly from raw text of the last system and (noisy) user responses. Our initial results, in the restaurant domain, show that it is indeed possible to induce reasonable dialogue behaviour with an approach that aims for high levels of automation in dialogue control for intelligent interactive agents.",
            "url": "http://arxiv.org/abs/1601.04574",
            "publicationTitle": "arXiv:1601.04574 [cs]",
            "extra": "arXiv: 1601.04574\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "SimpleDS"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1106.0676v1": [
        {
            "key": "L6ENZZSK",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "M.",
                    "lastName": "Kearns",
                    "creatorType": "author"
                },
                {
                    "firstName": "D.",
                    "lastName": "Litman",
                    "creatorType": "author"
                },
                {
                    "firstName": "S.",
                    "lastName": "Singh",
                    "creatorType": "author"
                },
                {
                    "firstName": "M.",
                    "lastName": "Walker",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Machine Learning",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Optimizing Dialogue Management with Reinforcement Learning: Experiments with the NJFun System",
            "date": "2002-02-01",
            "abstractNote": "Designing the dialogue policy of a spoken dialogue system involves many nontrivial choices. This paper presents a reinforcement learning approach for automatically optimizing a dialogue policy, which addresses the technical challenges in applying reinforcement learning to a working dialogue system with human users. We report on the design, construction and empirical evaluation of NJFun, an experimental spoken dialogue system that provides users with access to information about fun things to do in New Jersey. Our results show that by optimizing its performance via reinforcement learning, NJFun measurably improves system performance.",
            "url": "http://arxiv.org/abs/1106.0676",
            "DOI": "10.1613/jair.859",
            "publicationTitle": "Journal of Artificial Intelligence Research",
            "extra": "arXiv: 1106.0676\nversion: 1",
            "volume": "16",
            "pages": "105\u2013133",
            "ISSN": "1076-9757",
            "journalAbbreviation": "jair",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Optimizing Dialogue Management with Reinforcement Learning"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2Fcmp-lg%2F9708009v1": [
        {
            "key": "X7Q92F3D",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Jens-Uwe",
                    "lastName": "Moeller",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "DIA-MOLE: An Unsupervised Learning Approach to Adaptive Dialogue Models for Spoken Dialogue Systems",
            "date": "1997-08-18",
            "abstractNote": "The DIAlogue MOdel Learning Environment supports an engineering-oriented approach towards dialogue modelling for a spoken-language interface. Major steps towards dialogue models is to know about the basic units that are used to construct a dialogue model and possible sequences. In difference to many other approaches a set of dialogue acts is not predefined by any theory or manually during the engineering process, but is learned from data that are available in an avised spoken dialogue system. The architecture is outlined and the approach is applied to the domain of appointment scheduling. Even though based on a word correctness of about 70% predictability of dialogue acts in DIA-MOLE turns out to be comparable to human-assigned dialogue acts.",
            "url": "http://arxiv.org/abs/cmp-lg/9708009",
            "publicationTitle": "arXiv:cmp-lg/9708009",
            "extra": "arXiv: cmp-lg/9708009\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "DIA-MOLE"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1902.00771v1": [
        {
            "key": "EPL4FA2F",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Adi",
                    "lastName": "Botea",
                    "creatorType": "author"
                },
                {
                    "firstName": "Christian",
                    "lastName": "Muise",
                    "creatorType": "author"
                },
                {
                    "firstName": "Shubham",
                    "lastName": "Agarwal",
                    "creatorType": "author"
                },
                {
                    "firstName": "Oznur",
                    "lastName": "Alkan",
                    "creatorType": "author"
                },
                {
                    "firstName": "Ondrej",
                    "lastName": "Bajgar",
                    "creatorType": "author"
                },
                {
                    "firstName": "Elizabeth",
                    "lastName": "Daly",
                    "creatorType": "author"
                },
                {
                    "firstName": "Akihiro",
                    "lastName": "Kishimoto",
                    "creatorType": "author"
                },
                {
                    "firstName": "Luis",
                    "lastName": "Lastras",
                    "creatorType": "author"
                },
                {
                    "firstName": "Radu",
                    "lastName": "Marinescu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Josef",
                    "lastName": "Ondrej",
                    "creatorType": "author"
                },
                {
                    "firstName": "Pablo",
                    "lastName": "Pedemonte",
                    "creatorType": "author"
                },
                {
                    "firstName": "Miroslav",
                    "lastName": "Vodolan",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Generating Dialogue Agents via Automated Planning",
            "date": "2019-02-02",
            "abstractNote": "Dialogue systems have many applications such as customer support or question answering. Typically they have been limited to shallow single turn interactions. However more advanced applications such as career coaching or planning a trip require a much more complex multi-turn dialogue. Current limitations of conversational systems have made it difficult to support applications that require personalization, customization and context dependent interactions. We tackle this challenging problem by using domain-independent AI planning to automatically create dialogue plans, customized to guide a dialogue towards achieving a given goal. The input includes a library of atomic dialogue actions, an initial state of the dialogue, and a goal. Dialogue plans are plugged into a dialogue system capable to orchestrate their execution. Use cases demonstrate the viability of the approach. Our work on dialogue planning has been integrated into a product, and it is in the process of being deployed into another.",
            "url": "http://arxiv.org/abs/1902.00771",
            "publicationTitle": "arXiv:1902.00771 [cs]",
            "extra": "arXiv: 1902.00771\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1907.03020v1": [
        {
            "key": "9Q2AMSY6",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Shachi",
                    "lastName": "Paul",
                    "creatorType": "author"
                },
                {
                    "firstName": "Rahul",
                    "lastName": "Goel",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dilek",
                    "lastName": "Hakkani-T\u00fcr",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Towards Universal Dialogue Act Tagging for Task-Oriented Dialogues",
            "date": "2019-07-05",
            "abstractNote": "Machine learning approaches for building task-oriented dialogue systems require large conversational datasets with labels to train on. We are interested in building task-oriented dialogue systems from human-human conversations, which may be available in ample amounts in existing customer care center logs or can be collected from crowd workers. Annotating these datasets can be prohibitively expensive. Recently multiple annotated task-oriented human-machine dialogue datasets have been released, however their annotation schema varies across different collections, even for well-defined categories such as dialogue acts (DAs). We propose a Universal DA schema for task-oriented dialogues and align existing annotated datasets with our schema. Our aim is to train a Universal DA tagger (U-DAT) for task-oriented dialogues and use it for tagging human-human conversations. We investigate multiple datasets, propose manual and automated approaches for aligning the different schema, and present results on a target corpus of human-human dialogues. In unsupervised learning experiments we achieve an F1 score of 54.1% on system turns in human-human dialogues. In a semi-supervised setup, the F1 score increases to 57.7% which would otherwise require at least 1.7K manually annotated turns. For new domains, we show further improvements when unlabeled or labeled target domain data is available.",
            "url": "http://arxiv.org/abs/1907.03020",
            "publicationTitle": "arXiv:1907.03020 [cs]",
            "extra": "arXiv: 1907.03020\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2107.08685v1": [
        {
            "key": "XVGE4JAD",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Nyoungwoo",
                    "lastName": "Lee",
                    "creatorType": "author"
                },
                {
                    "firstName": "Suwon",
                    "lastName": "Shin",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jaegul",
                    "lastName": "Choo",
                    "creatorType": "author"
                },
                {
                    "firstName": "Ho-Jin",
                    "lastName": "Choi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Sung-Hyun",
                    "lastName": "Myaeng",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Constructing Multi-Modal Dialogue Dataset by Replacing Text with Semantically Relevant Images",
            "date": "2021-07-19",
            "abstractNote": "In multi-modal dialogue systems, it is important to allow the use of images as part of a multi-turn conversation. Training such dialogue systems generally requires a large-scale dataset consisting of multi-turn dialogues that involve images, but such datasets rarely exist. In response, this paper proposes a 45k multi-modal dialogue dataset created with minimal human intervention. Our method to create such a dataset consists of (1) preparing and pre-processing text dialogue datasets, (2) creating image-mixed dialogues by using a text-to-image replacement technique, and (3) employing a contextual-similarity-based filtering step to ensure the contextual coherence of the dataset. To evaluate the validity of our dataset, we devise a simple retrieval model for dialogue sentence prediction tasks. Automatic metrics and human evaluation results on such tasks show that our dataset can be effectively used as training data for multi-modal dialogue systems which require an understanding of images and text in a context-aware manner. Our dataset and generation code is available at https://github.com/shh1574/multi-modal-dialogue-dataset.",
            "url": "http://arxiv.org/abs/2107.08685",
            "publicationTitle": "arXiv:2107.08685 [cs]",
            "extra": "arXiv: 2107.08685\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1801.04871v1": [
        {
            "key": "J6GF87J4",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Pararth",
                    "lastName": "Shah",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dilek",
                    "lastName": "Hakkani-T\u00fcr",
                    "creatorType": "author"
                },
                {
                    "firstName": "Gokhan",
                    "lastName": "T\u00fcr",
                    "creatorType": "author"
                },
                {
                    "firstName": "Abhinav",
                    "lastName": "Rastogi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Ankur",
                    "lastName": "Bapna",
                    "creatorType": "author"
                },
                {
                    "firstName": "Neha",
                    "lastName": "Nayak",
                    "creatorType": "author"
                },
                {
                    "firstName": "Larry",
                    "lastName": "Heck",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Building a Conversational Agent Overnight with Dialogue Self-Play",
            "date": "2018-01-15",
            "abstractNote": "We propose Machines Talking To Machines (M2M), a framework combining automation and crowdsourcing to rapidly bootstrap end-to-end dialogue agents for goal-oriented dialogues in arbitrary domains. M2M scales to new tasks with just a task schema and an API client from the dialogue system developer, but it is also customizable to cater to task-specific interactions. Compared to the Wizard-of-Oz approach for data collection, M2M achieves greater diversity and coverage of salient dialogue flows while maintaining the naturalness of individual utterances. In the first phase, a simulated user bot and a domain-agnostic system bot converse to exhaustively generate dialogue \"outlines\", i.e. sequences of template utterances and their semantic parses. In the second phase, crowd workers provide contextual rewrites of the dialogues to make the utterances more natural while preserving their meaning. The entire process can finish within a few hours. We propose a new corpus of 3,000 dialogues spanning 2 domains collected with M2M, and present comparisons with popular dialogue datasets on the quality and diversity of the surface forms and dialogue flows.",
            "url": "http://arxiv.org/abs/1801.04871",
            "publicationTitle": "arXiv:1801.04871 [cs]",
            "extra": "arXiv: 1801.04871\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1812.00350v1": [
        {
            "key": "FPFVET6I",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Heriberto",
                    "lastName": "Cuay\u00e1huitl",
                    "creatorType": "author"
                },
                {
                    "firstName": "Seonghan",
                    "lastName": "Ryu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Donghyeon",
                    "lastName": "Lee",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jihie",
                    "lastName": "Kim",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "A Study on Dialogue Reward Prediction for Open-Ended Conversational Agents",
            "date": "2018-12-02",
            "abstractNote": "The amount of dialogue history to include in a conversational agent is often underestimated and/or set in an empirical and thus possibly naive way. This suggests that principled investigations into optimal context windows are urgently needed given that the amount of dialogue history and corresponding representations can play an important role in the overall performance of a conversational system. This paper studies the amount of history required by conversational agents for reliably predicting dialogue rewards. The task of dialogue reward prediction is chosen for investigating the effects of varying amounts of dialogue history and their impact on system performance. Experimental results using a dataset of 18K human-human dialogues report that lengthy dialogue histories of at least 10 sentences are preferred (25 sentences being the best in our experiments) over short ones, and that lengthy histories are useful for training dialogue reward predictors with strong positive correlations between target dialogue rewards and predicted ones.",
            "url": "http://arxiv.org/abs/1812.00350",
            "publicationTitle": "arXiv:1812.00350 [cs]",
            "extra": "arXiv: 1812.00350\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2010.03994v1": [
        {
            "key": "Z3GZ5758",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Lishan",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zheng",
                    "lastName": "Ye",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jinghui",
                    "lastName": "Qin",
                    "creatorType": "author"
                },
                {
                    "firstName": "Liang",
                    "lastName": "Lin",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaodan",
                    "lastName": "Liang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "GRADE: Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems",
            "date": "2020-10-08",
            "abstractNote": "Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric GRADE, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, GRADE incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our GRADE significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgements. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.",
            "url": "http://arxiv.org/abs/2010.03994",
            "publicationTitle": "arXiv:2010.03994 [cs]",
            "extra": "arXiv: 2010.03994\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "GRADE"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1909.02265v1": [
        {
            "key": "2LQK956S",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Tho Luong",
                    "lastName": "Chi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Phuong",
                    "lastName": "Le-Hong",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Towards Task-Oriented Dialogue in Mixed Domains",
            "date": "2019-09-05",
            "abstractNote": "This work investigates the task-oriented dialogue problem in mixed-domain settings. We study the effect of alternating between different domains in sequences of dialogue turns using two related state-of-the-art dialogue systems. We first show that a specialized state tracking component in multiple domains plays an important role and gives better results than an end-to-end task-oriented dialogue system. We then propose a hybrid system which is able to improve the belief tracking accuracy of about 28% of average absolute point on a standard multi-domain dialogue dataset. These experimental results give some useful insights for improving our commercial chatbot platform FPT.AI, which is currently deployed for many practical chatbot applications.",
            "url": "http://arxiv.org/abs/1909.02265",
            "publicationTitle": "arXiv:1909.02265 [cs]",
            "extra": "arXiv: 1909.02265\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1804.07691v1": [
        {
            "key": "VMMY5RDU",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Kaixiang",
                    "lastName": "Mo",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yu",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Qiang",
                    "lastName": "Yang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Pascale",
                    "lastName": "Fung",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Cross-domain Dialogue Policy Transfer via Simultaneous Speech-act and Slot Alignment",
            "date": "2018-04-20",
            "abstractNote": "Dialogue policy transfer enables us to build dialogue policies in a target domain with little data by leveraging knowledge from a source domain with plenty of data. Dialogue sentences are usually represented by speech-acts and domain slots, and the dialogue policy transfer is usually achieved by assigning a slot mapping matrix based on human heuristics. However, existing dialogue policy transfer methods cannot transfer across dialogue domains with different speech-acts, for example, between systems built by different companies. Also, they depend on either common slots or slot entropy, which are not available when the source and target slots are totally disjoint and no database is available to calculate the slot entropy. To solve this problem, we propose a Policy tRansfer across dOMaIns and SpEech-acts (PROMISE) model, which is able to transfer dialogue policies across domains with different speech-acts and disjoint slots. The PROMISE model can learn to align different speech-acts and slots simultaneously, and it does not require common slots or the calculation of the slot entropy. Experiments on both real-world dialogue data and simulations demonstrate that PROMISE model can effectively transfer dialogue policies across domains with different speech-acts and disjoint slots.",
            "url": "http://arxiv.org/abs/1804.07691",
            "publicationTitle": "arXiv:1804.07691 [cs]",
            "extra": "arXiv: 1804.07691\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2010.05594v3": [
        {
            "key": "252RFETX",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Ting",
                    "lastName": "Han",
                    "creatorType": "author"
                },
                {
                    "firstName": "Ximing",
                    "lastName": "Liu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Ryuichi",
                    "lastName": "Takanobu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yixin",
                    "lastName": "Lian",
                    "creatorType": "author"
                },
                {
                    "firstName": "Chongxuan",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dazhen",
                    "lastName": "Wan",
                    "creatorType": "author"
                },
                {
                    "firstName": "Wei",
                    "lastName": "Peng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Minlie",
                    "lastName": "Huang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "MultiWOZ 2.3: A multi-domain task-oriented dialogue dataset enhanced with annotation corrections and co-reference annotation",
            "date": "2021-06-14",
            "abstractNote": "Task-oriented dialogue systems have made unprecedented progress with multiple state-of-the-art (SOTA) models underpinned by a number of publicly available MultiWOZ datasets. Dialogue state annotations are error-prone, leading to sub-optimal performance. Various efforts have been put in rectifying the annotation errors presented in the original MultiWOZ dataset. In this paper, we introduce MultiWOZ 2.3, in which we differentiate incorrect annotations in dialogue acts from dialogue states, identifying a lack of co-reference when publishing the updated dataset. To ensure consistency between dialogue acts and dialogue states, we implement co-reference features and unify annotations of dialogue acts and dialogue states. We update the state of the art performance of natural language understanding and dialogue state tracking on MultiWOZ 2.3, where the results show significant improvements than on previous versions of MultiWOZ datasets (2.0-2.2).",
            "url": "http://arxiv.org/abs/2010.05594",
            "publicationTitle": "arXiv:2010.05594 [cs]",
            "extra": "arXiv: 2010.05594\nversion: 3",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "MultiWOZ 2.3"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2012.07311v2": [
        {
            "key": "Y3B3DW8Q",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Yicheng",
                    "lastName": "Zou",
                    "creatorType": "author"
                },
                {
                    "firstName": "Lujun",
                    "lastName": "Zhao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yangyang",
                    "lastName": "Kang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jun",
                    "lastName": "Lin",
                    "creatorType": "author"
                },
                {
                    "firstName": "Minlong",
                    "lastName": "Peng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zhuoren",
                    "lastName": "Jiang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Changlong",
                    "lastName": "Sun",
                    "creatorType": "author"
                },
                {
                    "firstName": "Qi",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xuanjing",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaozhong",
                    "lastName": "Liu",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Topic-Oriented Spoken Dialogue Summarization for Customer Service with Saliency-Aware Topic Modeling",
            "date": "2021-06-25",
            "abstractNote": "In a customer service system, dialogue summarization can boost service efficiency by automatically creating summaries for long spoken dialogues in which customers and agents try to address issues about specific topics. In this work, we focus on topic-oriented dialogue summarization, which generates highly abstractive summaries that preserve the main ideas from dialogues. In spoken dialogues, abundant dialogue noise and common semantics could obscure the underlying informative content, making the general topic modeling approaches difficult to apply. In addition, for customer service, role-specific information matters and is an indispensable part of a summary. To effectively perform topic modeling on dialogues and capture multi-role information, in this work we propose a novel topic-augmented two-stage dialogue summarizer (TDS) jointly with a saliency-aware neural topic model (SATM) for topic-oriented summarization of customer service dialogues. Comprehensive studies on a real-world Chinese customer service dataset demonstrated the superiority of our method against several strong baselines.",
            "url": "http://arxiv.org/abs/2012.07311",
            "publicationTitle": "arXiv:2012.07311 [cs]",
            "extra": "arXiv: 2012.07311\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2103.03125v2": [
        {
            "key": "JJQCWVJE",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Zhuosheng",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Hai",
                    "lastName": "Zhao",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Human-Computer Interaction",
                    "type": 1
                }
            ],
            "title": "Advances in Multi-turn Dialogue Comprehension: A Survey",
            "date": "2021-10-12",
            "abstractNote": "Training machines to understand natural language and interact with humans is an elusive and essential task of artificial intelligence. A diversity of dialogue systems has been designed with the rapid development of deep learning techniques, especially the recent pre-trained language models (PrLMs). Among these studies, the fundamental yet challenging type of task is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. In this paper, we review the previous methods from the technical perspective of dialogue modeling for the dialogue comprehension task. We summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. Then, we discuss three typical patterns of dialogue modeling. In addition, we categorize dialogue-related pre-training techniques which are employed to enhance PrLMs in dialogue scenarios. Finally, we highlight the technical advances in recent years and point out the lessons from the empirical analysis and the prospects towards a new frontier of researches.",
            "url": "http://arxiv.org/abs/2103.03125",
            "publicationTitle": "arXiv:2103.03125 [cs]",
            "extra": "arXiv: 2103.03125\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Advances in Multi-turn Dialogue Comprehension"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2104.04947v1": [
        {
            "key": "XV6WUYL4",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Kun",
                    "lastName": "Xu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Han",
                    "lastName": "Wu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Linfeng",
                    "lastName": "Song",
                    "creatorType": "author"
                },
                {
                    "firstName": "Haisong",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Linqi",
                    "lastName": "Song",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dong",
                    "lastName": "Yu",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Conversational Semantic Role Labeling",
            "date": "2021-04-11",
            "abstractNote": "Semantic role labeling (SRL) aims to extract the arguments for each predicate in an input sentence. Traditional SRL can fail to analyze dialogues because it only works on every single sentence, while ellipsis and anaphora frequently occur in dialogues. To address this problem, we propose the conversational SRL task, where an argument can be the dialogue participants, a phrase in the dialogue history or the current sentence. As the existing SRL datasets are in the sentence level, we manually annotate semantic roles for 3,000 chit-chat dialogues (27,198 sentences) to boost the research in this direction. Experiments show that while traditional SRL systems (even with the help of coreference resolution or rewriting) perform poorly for analyzing dialogues, modeling dialogue histories and participants greatly helps the performance, indicating that adapting SRL to conversations is very promising for universal dialogue understanding. Our initial study by applying CSRL to two mainstream conversational tasks, dialogue response generation and dialogue context rewriting, also confirms the usefulness of CSRL.",
            "url": "http://arxiv.org/abs/2104.04947",
            "publicationTitle": "arXiv:2104.04947 [cs]",
            "extra": "arXiv: 2104.04947\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2110.04984v2": [
        {
            "key": "3NSTP4DR",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Zhuosheng",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Hai",
                    "lastName": "Zhao",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Human-Computer Interaction",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Information Retrieval",
                    "type": 1
                }
            ],
            "title": "Advances in Multi-turn Dialogue Comprehension: A Survey",
            "date": "2021-10-12",
            "abstractNote": "Training machines to understand natural language and interact with humans is an elusive and essential task of artificial intelligence. A diversity of dialogue systems has been designed with the rapid development of deep learning techniques, especially the recent pre-trained language models (PrLMs). Among these studies, the fundamental yet challenging type of task is dialogue comprehension whose role is to teach the machines to read and comprehend the dialogue context before responding. In this paper, we review the previous methods from the technical perspective of dialogue modeling for the dialogue comprehension task. We summarize the characteristics and challenges of dialogue comprehension in contrast to plain-text reading comprehension. Then, we discuss three typical patterns of dialogue modeling. In addition, we categorize dialogue-related pre-training techniques which are employed to enhance PrLMs in dialogue scenarios. Finally, we highlight the technical advances in recent years and point out the lessons from the empirical analysis and the prospects towards a new frontier of researches.",
            "url": "http://arxiv.org/abs/2110.04984",
            "publicationTitle": "arXiv:2110.04984 [cs]",
            "extra": "arXiv: 2110.04984\nversion: 2",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Advances in Multi-turn Dialogue Comprehension"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1612.00347v1": [
        {
            "key": "KESN86EC",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Dimitrios",
                    "lastName": "Kalatzis",
                    "creatorType": "author"
                },
                {
                    "firstName": "Arash",
                    "lastName": "Eshghi",
                    "creatorType": "author"
                },
                {
                    "firstName": "Oliver",
                    "lastName": "Lemon",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Human-Computer Interaction",
                    "type": 1
                }
            ],
            "title": "Bootstrapping incremental dialogue systems: using linguistic knowledge to learn from minimal data",
            "date": "2016-12-01",
            "abstractNote": "We present a method for inducing new dialogue systems from very small amounts of unannotated dialogue data, showing how word-level exploration using Reinforcement Learning (RL), combined with an incremental and semantic grammar - Dynamic Syntax (DS) - allows systems to discover, generate, and understand many new dialogue variants. The method avoids the use of expensive and time-consuming dialogue act annotations, and supports more natural (incremental) dialogues than turn-based systems. Here, language generation and dialogue management are treated as a joint decision/optimisation problem, and the MDP model for RL is constructed automatically. With an implemented system, we show that this method enables a wide range of dialogue variations to be automatically captured, even when the system is trained from only a single dialogue. The variants include question-answer pairs, over- and under-answering, self- and other-corrections, clarification interaction, split-utterances, and ellipsis. This generalisation property results from the structural knowledge and constraints present within the DS grammar, and highlights some limitations of recent systems built using machine learning techniques only.",
            "url": "http://arxiv.org/abs/1612.00347",
            "publicationTitle": "arXiv:1612.00347 [cs]",
            "extra": "arXiv: 1612.00347\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Bootstrapping incremental dialogue systems"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2010.08738v1": [
        {
            "key": "JS8DRCU2",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Jun",
                    "lastName": "Quan",
                    "creatorType": "author"
                },
                {
                    "firstName": "Shian",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Qian",
                    "lastName": "Cao",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zizhong",
                    "lastName": "Li",
                    "creatorType": "author"
                },
                {
                    "firstName": "Deyi",
                    "lastName": "Xiong",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "RiSAWOZ: A Large-Scale Multi-Domain Wizard-of-Oz Dataset with Rich Semantic Annotations for Task-Oriented Dialogue Modeling",
            "date": "2020-10-17",
            "abstractNote": "In order to alleviate the shortage of multi-domain data and to capture discourse phenomena for task-oriented dialogue modeling, we propose RiSAWOZ, a large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets. Both single- and multi-domain dialogues are constructed, accounting for 65% and 35%, respectively. Each dialogue is labeled with comprehensive dialogue annotations, including dialogue goal in the form of natural language description, domain, dialogue states and acts at both the user and system side. In addition to traditional dialogue annotations, we especially provide linguistic annotations on discourse phenomena, e.g., ellipsis and coreference, in dialogues, which are useful for dialogue coreference and ellipsis resolution tasks. Apart from the fully annotated dataset, we also present a detailed description of the data collection procedure, statistics and analysis of the dataset. A series of benchmark models and results are reported, including natural language understanding (intent detection & slot filling), dialogue state tracking and dialogue context-to-text generation, as well as coreference and ellipsis resolution, which facilitate the baseline comparison for future research on this corpus.",
            "url": "http://arxiv.org/abs/2010.08738",
            "publicationTitle": "arXiv:2010.08738 [cs]",
            "extra": "arXiv: 2010.08738\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "RiSAWOZ"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1812.01144v1": [
        {
            "key": "3SEQRYJA",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Philip R.",
                    "lastName": "Cohen",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Back to the Future for Dialogue Research: A Position Paper",
            "date": "2018-12-03",
            "abstractNote": "This short position paper is intended to provide a critique of current approaches to dialogue, as well as a roadmap for collaborative dialogue research. It is unapologetically opinionated, but informed by 40 years of dialogue re-search. No attempt is made to be comprehensive. The paper will discuss current research into building so-called \"chatbots\", slot-filling dialogue systems, and plan-based dialogue systems. For further discussion of some of these issues, please see (Allen et al., in press).",
            "url": "http://arxiv.org/abs/1812.01144",
            "publicationTitle": "arXiv:1812.01144 [cs]",
            "extra": "arXiv: 1812.01144\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Back to the Future for Dialogue Research"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2011.03259v1": [
        {
            "key": "K9GE9AMT",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Jan",
                    "lastName": "Pichl",
                    "creatorType": "author"
                },
                {
                    "firstName": "Petr",
                    "lastName": "Marek",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jakub",
                    "lastName": "Konr\u00e1d",
                    "creatorType": "author"
                },
                {
                    "firstName": "Martin",
                    "lastName": "Matul\u00edk",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jan",
                    "lastName": "\u0160ediv\u00fd",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Alquist 2.0: Alexa Prize Socialbot Based on Sub-Dialogue Models",
            "date": "2020-11-06",
            "abstractNote": "This paper presents the second version of the dialogue system named Alquist competing in Amazon Alexa Prize 2018. We introduce a system leveraging ontology-based topic structure called topic nodes. Each of the nodes consists of several sub-dialogues, and each sub-dialogue has its own LSTM-based model for dialogue management. The sub-dialogues can be triggered according to the topic hierarchy or a user intent which allows the bot to create a unique experience during each session.",
            "url": "http://arxiv.org/abs/2011.03259",
            "publicationTitle": "arXiv:2011.03259 [cs]",
            "extra": "arXiv: 2011.03259\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "Alquist 2.0"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1106.0241v1": [
        {
            "key": "NG2QDC76",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "M. A.",
                    "lastName": "Walker",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "An Application of Reinforcement Learning to Dialogue Strategy Selection in a Spoken Dialogue System for Email",
            "date": "2000-06-01",
            "abstractNote": "This paper describes a novel method by which a spoken dialogue system can learn to choose an optimal dialogue strategy from its experience interacting with human users. The method is based on a combination of reinforcement learning and performance modeling of spoken dialogue systems. The reinforcement learning component applies Q-learning (Watkins, 1989), while the performance modeling component applies the PARADISE evaluation framework (Walker et al., 1997) to learn the performance function (reward) used in reinforcement learning. We illustrate the method with a spoken dialogue system named ELVIS (EmaiL Voice Interactive System), that supports access to email over the phone. We conduct a set of experiments for training an optimal dialogue strategy on a corpus of 219 dialogues in which human users interact with ELVIS over the phone. We then test that strategy on a corpus of 18 dialogues. We show that ELVIS can learn to optimize its strategy selection for agent initiative, for reading messages, and for summarizing email folders.",
            "url": "http://arxiv.org/abs/1106.0241",
            "DOI": "10.1613/jair.713",
            "publicationTitle": "Journal of Artificial Intelligence Research",
            "extra": "arXiv: 1106.0241\nversion: 1",
            "volume": "12",
            "pages": "387\u2013416",
            "ISSN": "1076-9757",
            "journalAbbreviation": "jair",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1811.04369v1": [
        {
            "key": "HJVSZNDH",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Izzeddin",
                    "lastName": "Gur",
                    "creatorType": "author"
                },
                {
                    "firstName": "Dilek",
                    "lastName": "Hakkani-Tur",
                    "creatorType": "author"
                },
                {
                    "firstName": "Gokhan",
                    "lastName": "Tur",
                    "creatorType": "author"
                },
                {
                    "firstName": "Pararth",
                    "lastName": "Shah",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Machine Learning",
                    "type": 1
                }
            ],
            "title": "User Modeling for Task Oriented Dialogues",
            "date": "2018-11-11",
            "abstractNote": "We introduce end-to-end neural network based models for simulating users of task-oriented dialogue systems. User simulation in dialogue systems is crucial from two different perspectives: (i) automatic evaluation of different dialogue models, and (ii) training task-oriented dialogue systems. We design a hierarchical sequence-to-sequence model that first encodes the initial user goal and system turns into fixed length representations using Recurrent Neural Networks (RNN). It then encodes the dialogue history using another RNN layer. At each turn, user responses are decoded from the hidden representations of the dialogue level RNN. This hierarchical user simulator (HUS) approach allows the model to capture undiscovered parts of the user goal without the need of an explicit dialogue state tracking. We further develop several variants by utilizing a latent variable model to inject random variations into user responses to promote diversity in simulated user responses and a novel goal regularization mechanism to penalize divergence of user responses from the initial user goal. We evaluate the proposed models on movie ticket booking domain by systematically interacting each user simulator with various dialogue system policies trained with different objectives and users.",
            "url": "http://arxiv.org/abs/1811.04369",
            "publicationTitle": "arXiv:1811.04369 [cs]",
            "extra": "arXiv: 1811.04369\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2103.06648v1": [
        {
            "key": "DF3UIIIS",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Hyunmin",
                    "lastName": "Jeon",
                    "creatorType": "author"
                },
                {
                    "firstName": "Gary Geunbae",
                    "lastName": "Lee",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Domain State Tracking for a Simplified Dialogue System",
            "date": "2021-03-11",
            "abstractNote": "Task-oriented dialogue systems aim to help users achieve their goals in specific domains. Recent neural dialogue systems use the entire dialogue history for abundant contextual information accumulated over multiple conversational turns. However, the dialogue history becomes increasingly longer as the number of turns increases, thereby increasing memory usage and computational costs. In this paper, we present DoTS (Domain State Tracking for a Simplified Dialogue System), a task-oriented dialogue system that uses a simplified input context instead of the entire dialogue history. However, neglecting the dialogue history can result in a loss of contextual information from previous conversational turns. To address this issue, DoTS tracks the domain state in addition to the belief state and uses it for the input context. Using this simplified input, DoTS improves the inform rate and success rate by 1.09 points and 1.24 points, respectively, compared to the previous state-of-the-art model on MultiWOZ, which is a well-known benchmark.",
            "url": "http://arxiv.org/abs/2103.06648",
            "publicationTitle": "arXiv:2103.06648 [cs]",
            "extra": "arXiv: 2103.06648\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2108.01547v1": [
        {
            "key": "WMSGZVK3",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Hao",
                    "lastName": "Zhou",
                    "creatorType": "author"
                },
                {
                    "firstName": "Pei",
                    "lastName": "Ke",
                    "creatorType": "author"
                },
                {
                    "firstName": "Zheng",
                    "lastName": "Zhang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yuxian",
                    "lastName": "Gu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yinhe",
                    "lastName": "Zheng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Chujie",
                    "lastName": "Zheng",
                    "creatorType": "author"
                },
                {
                    "firstName": "Yida",
                    "lastName": "Wang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Chen Henry",
                    "lastName": "Wu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Hao",
                    "lastName": "Sun",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaocong",
                    "lastName": "Yang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Bosi",
                    "lastName": "Wen",
                    "creatorType": "author"
                },
                {
                    "firstName": "Xiaoyan",
                    "lastName": "Zhu",
                    "creatorType": "author"
                },
                {
                    "firstName": "Minlie",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Jie",
                    "lastName": "Tang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "EVA: An Open-Domain Chinese Dialogue System with Large-Scale Generative Pre-Training",
            "date": "2021-08-03",
            "abstractNote": "Although pre-trained language models have remarkably enhanced the generation ability of dialogue systems, open-domain Chinese dialogue systems are still limited by the dialogue data and the model size compared with English ones. In this paper, we propose EVA, a Chinese dialogue system that contains the largest Chinese pre-trained dialogue model with 2.8B parameters. To build this model, we collect the largest Chinese dialogue dataset named WDC-Dialogue from various public social media. This dataset contains 1.4B context-response pairs and is used as the pre-training corpus of EVA. Extensive experiments on automatic and human evaluation show that EVA outperforms other Chinese pre-trained dialogue models especially in the multi-turn interaction of human-bot conversations.",
            "url": "http://arxiv.org/abs/2108.01547",
            "publicationTitle": "arXiv:2108.01547 [cs]",
            "extra": "arXiv: 2108.01547\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "EVA"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2Fcmp-lg%2F9704004v1": [
        {
            "key": "VQZ954R3",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Marilyn A.",
                    "lastName": "Walker",
                    "creatorType": "author"
                },
                {
                    "firstName": "Diane J.",
                    "lastName": "Litman",
                    "creatorType": "author"
                },
                {
                    "firstName": "Candace A.",
                    "lastName": "Kamm",
                    "creatorType": "author"
                },
                {
                    "firstName": "Alicia",
                    "lastName": "Abella",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "PARADISE: A Framework for Evaluating Spoken Dialogue Agents",
            "date": "1997-04-15",
            "abstractNote": "This paper presents PARADISE (PARAdigm for DIalogue System Evaluation), a general framework for evaluating spoken dialogue agents. The framework decouples task requirements from an agent's dialogue behaviors, supports comparisons among dialogue strategies, enables the calculation of performance over subdialogues and whole dialogues, specifies the relative contribution of various factors to performance, and makes it possible to compare agents performing different tasks by normalizing for task complexity.",
            "url": "http://arxiv.org/abs/cmp-lg/9704004",
            "publicationTitle": "arXiv:cmp-lg/9704004",
            "extra": "arXiv: cmp-lg/9704004\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30",
            "shortTitle": "PARADISE"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1704.07130v1": [
        {
            "key": "9K4LS8ZC",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "He",
                    "lastName": "He",
                    "creatorType": "author"
                },
                {
                    "firstName": "Anusha",
                    "lastName": "Balakrishnan",
                    "creatorType": "author"
                },
                {
                    "firstName": "Mihail",
                    "lastName": "Eric",
                    "creatorType": "author"
                },
                {
                    "firstName": "Percy",
                    "lastName": "Liang",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Learning Symmetric Collaborative Dialogue Agents with Dynamic Knowledge Graph Embeddings",
            "date": "2017-04-24",
            "abstractNote": "We study a symmetric collaborative dialogue setting in which two agents, each with private knowledge, must strategically communicate to achieve a common goal. The open-ended dialogue state in this setting poses new challenges for existing dialogue systems. We collected a dataset of 11K human-human dialogues, which exhibits interesting lexical, semantic, and strategic elements. To model both structured knowledge and unstructured language, we propose a neural model with dynamic knowledge graph embeddings that evolve as the dialogue progresses. Automatic and human evaluations show that our model is both more effective at achieving the goal and more human-like than baseline neural and rule-based models.",
            "url": "http://arxiv.org/abs/1704.07130",
            "publicationTitle": "arXiv:1704.07130 [cs]",
            "extra": "arXiv: 1704.07130\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F2106.08723v1": [
        {
            "key": "597MFT3R",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Ting",
                    "lastName": "Han",
                    "creatorType": "author"
                },
                {
                    "firstName": "Chongxuan",
                    "lastName": "Huang",
                    "creatorType": "author"
                },
                {
                    "firstName": "Wei",
                    "lastName": "Peng",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                }
            ],
            "title": "Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking",
            "date": "2021-06-16",
            "abstractNote": "Dialogue State Tracking (DST), which is the process of inferring user goals by estimating belief states given the dialogue history, plays a critical role in task-oriented dialogue systems. A coreference phenomenon observed in multi-turn conversations is not addressed by existing DST models, leading to sub-optimal performances. In this paper, we propose Coreference Dialogue State Tracker (CDST) that explicitly models the coreference feature. In particular, at each turn, the proposed model jointly predicts the coreferred domain-slot pair and extracts the coreference values from the dialogue context. Experimental results on MultiWOZ 2.1 dataset show that the proposed model achieves the state-of-the-art joint goal accuracy of 56.47%.",
            "url": "http://arxiv.org/abs/2106.08723",
            "publicationTitle": "arXiv:2106.08723 [cs]",
            "extra": "arXiv: 2106.08723\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ],
    "http%3A%2F%2Farxiv.org%2Fabs%2F1905.07687v1": [
        {
            "key": "GWCCZKPJ",
            "version": 0,
            "itemType": "journalArticle",
            "creators": [
                {
                    "firstName": "Chien-Sheng",
                    "lastName": "Wu",
                    "creatorType": "author"
                }
            ],
            "tags": [
                {
                    "tag": "Computer Science - Computation and Language",
                    "type": 1
                },
                {
                    "tag": "Computer Science - Artificial Intelligence",
                    "type": 1
                }
            ],
            "title": "Learning to Memorize in Neural Task-Oriented Dialogue Systems",
            "date": "2019-05-19",
            "abstractNote": "In this thesis, we leverage the neural copy mechanism and memory-augmented neural networks (MANNs) to address existing challenge of neural task-oriented dialogue learning. We show the effectiveness of our strategy by achieving good performance in multi-domain dialogue state tracking, retrieval-based dialogue systems, and generation-based dialogue systems. We first propose a transferable dialogue state generator (TRADE) that leverages its copy mechanism to get rid of dialogue ontology and share knowledge between domains. We also evaluate unseen domain dialogue state tracking and show that TRADE enables zero-shot dialogue state tracking and can adapt to new few-shot domains without forgetting the previous domains. Second, we utilize MANNs to improve retrieval-based dialogue learning. They are able to capture dialogue sequential dependencies and memorize long-term information. We also propose a recorded delexicalization copy strategy to replace real entity values with ordered entity types. Our models are shown to surpass other retrieval baselines, especially when the conversation has a large number of turns. Lastly, we tackle generation-based dialogue learning with two proposed models, the memory-to-sequence (Mem2Seq) and global-to-local memory pointer network (GLMP). Mem2Seq is the first model to combine multi-hop memory attention with the idea of the copy mechanism. GLMP further introduces the concept of response sketching and double pointers copying. We show that GLMP achieves the state-of-the-art performance on human evaluation.",
            "url": "http://arxiv.org/abs/1905.07687",
            "publicationTitle": "arXiv:1905.07687 [cs]",
            "extra": "arXiv: 1905.07687\nversion: 1",
            "libraryCatalog": "arXiv.org",
            "accessDate": "2021-10-30"
        }
    ]
}
